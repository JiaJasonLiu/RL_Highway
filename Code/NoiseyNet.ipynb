{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nDnBuLPwYin_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# this is funtional gaussian noise implimentation due to it being tensor it improve single agent rl such as dqn\n",
        "class NoisyNet(nn.Module):\n",
        "    def __init__(self, in_features, out_features, sigmaparam=0.4):#sigma is Ïƒi,j for all param where 3.2 INITIALISATION OF NOISY NETWORKS in the paper 0.017(for indimendent gaussain distri)\n",
        "      super(NoisyNet, self).__init__()\n",
        "      self.in_features = in_features\n",
        "      self.out_features = out_features\n",
        "      self.sigmaparam = sigmaparam\n",
        "\n",
        "      # learnable param (sigma and mu)\n",
        "\n",
        "      self.weight_mu = nn.Parameter(torch.empty(out_features, in_features))\n",
        "      self.bias_mu = nn.Parameter(torch.empty(out_features))\n",
        "      self.sigma_weight = nn.Parameter(torch.empty(out_features, in_features))\n",
        "      self.sigma_bias = nn.Parameter(torch.empty(out_features))\n",
        "\n",
        "      # noise param using a distribution\n",
        "\n",
        "      self.register_buffer(\"epsilon_weight_middle\", torch.empty(out_features, in_features))\n",
        "      self.register_buffer(\"epsilon_bias\", torch.empty(out_features))\n",
        "      self.reset_parameters()\n",
        "      self.factorized_noise()\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      # xavier uniform due to DQN sigma activation function for actions\n",
        "      mu_range = 1 / (self.in_features ** 0.5)\n",
        "      self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
        "      self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
        "      self.sigma_weight.data.fill_(self.sigmaparam)\n",
        "      self.sigma_bias.data.fill_(self.sigmaparam)\n",
        "    def noise(self,size):\n",
        "      factor_noise = torch.randn(size, device=self.weight_mu.device)\n",
        "      return factor_noise.sign().mul_(factor_noise.abs().sqrt_()) #this is the method they used in the paper f(x) = sign(x) * sqrt(abs(x))\n",
        "\n",
        "    def factorized_noise(self):\n",
        "      epsilon_in = self.noise(self.in_features)\n",
        "      epsilon_out = self.noise(self.out_features)\n",
        "      self.epsilon_weight = self.epsilon_weight_middle.copy_(epsilon_out.ger(epsilon_in))\n",
        "      self.epsilon_bias.copy_(epsilon_out)\n",
        "    def forward(self, input):\n",
        "      '''\n",
        "      Jason change this please, I am not sure how you defined trianing = true or false\n",
        "      this return currently present is for training = true where there are presence of noise ie. sigma*epsilon\n",
        "\n",
        "      For evaluation you will need to only return F.linear(input, self.weight_mu, self.bias_mu)\n",
        "      see below\n",
        "      '''\n",
        "      noisy_weigth = self.weight_mu + (self.sigma_weight * self.epsilon_weight)\n",
        "      noisy_bias = self.bias_mu + (self.sigma_bias * self.epsilon_bias)\n",
        "      return F.linear(input, noisy_weigth, noisy_bias)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def forward(self, input):\n",
        "    #   if self.training:\n",
        "    #       # (Optional) Resample noise on every forward pass\n",
        "    #     self.factorized_noise()\n",
        "\n",
        "    #     noisy_weight = self.weight_mu + (self.sigma_weight * self.epsilon_weight)\n",
        "    #     noisy_bias   = self.bias_mu   + (self.sigma_bias   * self.epsilon_bias)\n",
        "\n",
        "    #     return F.linear(input, noisy_weight, noisy_bias)\n",
        "    #   else:\n",
        "    #     # In evaluation mode, we typically want deterministic (noise-free) output\n",
        "    #     return F.linear(input, self.weight_mu, self.bias_mu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n728LYu1c9_y",
        "outputId": "c2925151-3bd3-43c7-adba-4ff18a095f9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Training Mode (model.train()) ===\n",
            "Output (training):\n",
            " tensor([[-0.5874,  0.4294],\n",
            "        [-1.9996,  1.8166],\n",
            "        [-1.0446,  0.5830],\n",
            "        [-3.4165,  2.9409]], grad_fn=<AddmmBackward0>) \n",
            "\n",
            "=== Evaluation Mode (model.eval()) ===\n",
            "Output (evaluation):\n",
            " tensor([[-0.5874,  0.4294],\n",
            "        [-1.9996,  1.8166],\n",
            "        [-1.0446,  0.5830],\n",
            "        [-3.4165,  2.9409]], grad_fn=<AddmmBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        # Replace nn.Linear with NoisyNetIndependent\n",
        "        self.fc1 = NoisyNet(in_dim, hidden_dim)\n",
        "        self.fc2 = NoisyNet(hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def main():\n",
        "    # Create a random tensor with batch_size=4 and in_dim=3\n",
        "    input_data = torch.randn(4, 3)\n",
        "\n",
        "    # Initialize our model\n",
        "    model = SimpleModel(in_dim=3, hidden_dim=5, out_dim=2)\n",
        "\n",
        "    print(\"=== Training Mode (model.train()) ===\")\n",
        "    model.train()\n",
        "    output_train = model(input_data)\n",
        "    print(\"Output (training):\\n\", output_train, \"\\n\")\n",
        "\n",
        "    print(\"=== Evaluation Mode (model.eval()) ===\")\n",
        "    model.eval()\n",
        "    output_eval = model(input_data)\n",
        "    print(\"Output (evaluation):\\n\", output_eval, \"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbjjzMiNkzKV",
        "outputId": "60c52d8f-75de-4a91-f495-774bbf136e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Training Mode (model.train()) ===\n",
            "Output (training):\n",
            "tensor([[ -2.3016,   4.0164,   5.4170, -11.3774],\n",
            "        [ -1.3299,   2.3595,   3.2125,  -6.6374]], grad_fn=<AddmmBackward0>) \n",
            "\n",
            "=== Evaluation Mode (model.eval()) ===\n",
            "Output (evaluation):\n",
            "tensor([[ -2.9934,   5.2817,   7.1703, -15.0740],\n",
            "        [ -0.9288,   1.6107,   2.2091,  -4.6028]], grad_fn=<AddmmBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super(CNN, self).__init__()\n",
        "        # greyscale Image is(stack,height,width)\n",
        "        stack, height, width = input_shape\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(stack,16,kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16,32,kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32,64, kernel_size=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # This is for finding the size to dense more robust compared to decision manually\n",
        "        with torch.no_grad():\n",
        "                # Torch uses(1,channels,height,width)\n",
        "                test = torch.zeros(1, stack, height, width)\n",
        "                find_conv_size = self.conv(test)\n",
        "                conv_size = find_conv_size.numel()\n",
        "        '''\n",
        "        This is the line to change for the CNN\n",
        "\n",
        "        '''\n",
        "        # self.out1 = nn.Linear(conv_size,num_actions)\n",
        "        self.out1 = NoisyNet(conv_size,num_actions)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.out1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Suppose your input shape is (stack=1, height=84, width=84)\n",
        "    input_shape = (1, 84, 84)\n",
        "    num_actions = 4\n",
        "\n",
        "    # Instantiate the CNN with NoisyNet\n",
        "    model = CNN(input_shape, num_actions)\n",
        "\n",
        "    # Switch to train mode\n",
        "    model.train()\n",
        "    train_input = torch.randn(2, *input_shape)  # batch_size=2, shape=(2,1,84,84)\n",
        "    train_output = model(train_input)\n",
        "    print(\"=== Training Mode (model.train()) ===\")\n",
        "    print(\"Output (training):\")\n",
        "    print(train_output, \"\\n\")\n",
        "\n",
        "    # Switch to eval mode\n",
        "    model.eval()\n",
        "    eval_input = torch.randn(2, *input_shape)  # new random input\n",
        "    eval_output = model(eval_input)\n",
        "    print(\"=== Evaluation Mode (model.eval()) ===\")\n",
        "    print(\"Output (evaluation):\")\n",
        "    print(eval_output, \"\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
