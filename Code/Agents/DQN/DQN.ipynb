{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Implmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # Install environment and agent\n",
    "# !pip install highway-env\n",
    "# !pip install --upgrade sympy torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Learning using existing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the pesudocode that will be followed when creating the DQN\n",
    "\n",
    "Useful: https://www.youtube.com/watch?v=RVMpm86equc&list=PL58zEckBH8fCMIVzQCRSZVPUp3ZAVagWi&index=2\n",
    "\n",
    "https://github.com/saashanair/rl-series/tree/master/dqn\n",
    "\n",
    "https://github.com/johnnycode8/gym_solutions/blob/main/frozen_lake_dql.py\n",
    "\n",
    "<img src=\"DQN.png\" style=\"width: 900px;\" align=\"left\"/>\n",
    "\n",
    "\n",
    "Potential Problems: https://www.reddit.com/r/reinforcementlearning/comments/1555wgi/dqn_loss_increasing_and_rewards_decreasing/\n",
    "\n",
    "\n",
    "For CNN:\n",
    "\n",
    "https://www.reddit.com/r/MachineLearning/comments/3l5qu7/rules_of_thumb_for_cnn_architectures/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class SumTree:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros( 2 * capacity - 1 )\n",
    "        self.data = np.zeros( capacity, dtype=object )\n",
    "        self.writer = 0\n",
    "\n",
    "    # propagate upwards to update the sum values\n",
    "    def _propagate(self, index, change):\n",
    "        parent = (index - 1) // 2\n",
    "\n",
    "        self.tree[parent] += change\n",
    "\n",
    "        if parent != 0:\n",
    "            self._propagate(parent, change)\n",
    "\n",
    "    # get the leaf nodes (Transaction)\n",
    "    def _retrieve(self, index, s):\n",
    "        left = 2 * index + 1\n",
    "        right = left + 1\n",
    "\n",
    "        if left >= len(self.tree):\n",
    "            return index\n",
    "\n",
    "        if s <= self.tree[left]:\n",
    "            return self._retrieve(left, s)\n",
    "        else:\n",
    "            return self._retrieve(right, s-self.tree[left])\n",
    "\n",
    "    def total(self):\n",
    "        return self.tree[0]\n",
    "\n",
    "    def add(self, p, data):\n",
    "        index = self.write + self.capacity - 1\n",
    "\n",
    "        self.data[self.write] = data\n",
    "        self.update(index, p)\n",
    "\n",
    "        self.write += 1\n",
    "        # circular\n",
    "        if self.write >= self.capacity:\n",
    "            self.write = 0\n",
    "\n",
    "    def update(self, index, p):\n",
    "        change = p - self.tree[index]\n",
    "\n",
    "        self.tree[index] = p\n",
    "        self._propagate(index, change)\n",
    "\n",
    "    def get(self, s):\n",
    "        index = self._retrieve(0, s)\n",
    "        data_index = index - self.capacity + 1\n",
    "\n",
    "        return (index, self.tree[index], self.data[data_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import highway_env\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dist\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "# Define model\n",
    "class MLPNetwork(nn.Module):\n",
    "    def __init__(self, in_states, h1_nodes, out_actions):\n",
    "        super(MLPNetwork, self).__init__()\n",
    "\n",
    "        # Define network layers\n",
    "        self.fc1 = nn.Linear(in_states, h1_nodes)   # first fully connected layer\n",
    "        self.out = nn.Linear(h1_nodes, out_actions) # output layer\n",
    "        self.out2 = nn.Linear(out_actions, 1) # output layer\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) # Apply rectified linear unit (ReLU) activation\n",
    "        x = F.relu(self.out(x))         \n",
    "        x = self.out2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(CNN, self).__init__()\n",
    "        # greyscale Image is(stack,height,width)\n",
    "        stack, height, width = input_shape\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(stack,16,kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(16,32,kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32,64, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # This is for finding the size to dense more robust compared to decision manually\n",
    "        with torch.no_grad():\n",
    "                # Torch uses(1,channels,height,width)\n",
    "                test = torch.zeros(1, stack, height, width)\n",
    "                find_conv_size = self.conv(test)\n",
    "                conv_size = find_conv_size.numel()\n",
    "                \n",
    "        self.out1 = nn.Linear(conv_size,num_actions)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.out1(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define memory for Experience Replay\n",
    "# TODO: Prioritize, n-steps\n",
    "\n",
    "from collections.__init__ import namedtuple\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'done'))\n",
    "\n",
    "class ReplayMemory():\n",
    "    def __init__(self, config, transition_type=Transition):\n",
    "        self.capacity = config.get(\"capacity\", 1000)\n",
    "        self.index = 0\n",
    "        self.transition_type = transition_type\n",
    "        self.discount = config.get(\"discount\", 0.99)\n",
    "\n",
    "        self.memory = []\n",
    "        self.device = config.get(\"device\", torch.device(\"cpu\"))\n",
    "        self.n_steps = config.get(\"n_steps\", 2)\n",
    "    \n",
    "    def store(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "            self.index = len(self.memory) - 1\n",
    "        elif len(self.memory) > self.capacity:\n",
    "            self.memory = self.memory[:self.capacity]\n",
    "        # Faster than append and pop\n",
    "        self.memory[self.index] = self.transition_type(*args)\n",
    "        \n",
    "        self.index = (self.index+1)%self.capacity # for circular memory\n",
    "\n",
    "    def sample(self, batch_size, collapsed=True):\n",
    "        if batch_size >  len(self.memory):\n",
    "            batch_size = len(self.memory)\n",
    "            \n",
    "        if self.n_steps <= 1:\n",
    "            # Directly sample transitions\n",
    "            memories = random.sample(self.memory, batch_size)\n",
    "            return self.unwrap_transition(*memories)\n",
    "        else:\n",
    "            # Sample initial transition indexes\n",
    "            indexes = random.sample(range(len(self.memory)), batch_size)\n",
    "            # Get the batch of n-consecutive-transitions starting from sampled indexes\n",
    "            all_transitions = [self.memory[i:i+self.n_steps] for i in indexes]\n",
    "            \n",
    "            memories = map(self.collapse_n_steps, all_transitions) if collapsed else all_transitions\n",
    "\n",
    "            return self.unwrap_transition(*memories)\n",
    "        \n",
    "    def collapse_n_steps(self, transitions):\n",
    "        state, action, next_state, reward, done = transitions[0]\n",
    "        discount = self.discount\n",
    "        for transition in transitions[1:]:\n",
    "            if done:\n",
    "                break\n",
    "            else:\n",
    "                _, _, next_state, reward, done = transition\n",
    "                discount *= self.discount\n",
    "                reward += discount * reward\n",
    "        return state, action, next_state, reward, done\n",
    "    \n",
    "    def unwrap_transition(self, *transition):\n",
    "        state, action, next_state, reward, done = zip(*transition)\n",
    "        \n",
    "        states = torch.from_numpy(np.array(state)).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.array(action)).to(self.device)\n",
    "        next_states = torch.from_numpy(np.array(next_state)).float().to(self.device)\n",
    "        rewards = torch.from_numpy(np.array(reward)).float().to(self.device)\n",
    "        dones = torch.from_numpy(np.array(done)).to(self.device)\n",
    "\n",
    "        return states, actions, next_states, rewards, dones \n",
    "\n",
    "class PrioritizedReplayMemory(ReplayMemory):\n",
    "    def __init__(self, config, transition_type=Transition):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.capacity = config.get(\"capacity\", 1000)\n",
    "        self.tree = SumTree(self.capacity)\n",
    "        self.index = 0\n",
    "        self.transition_type = transition_type\n",
    "\n",
    "        self.memory = []\n",
    "        self.device = config.get(\"device\", torch.device(\"cpu\"))\n",
    "        \n",
    "        self.alpha = config.get(\"alpha\", 0.6)\n",
    "        self.beta = config.get(\"beta\", 0.2) #  will go to 1\n",
    "        self.max_priority = 1  # priority for new samples, init as eps\n",
    "        \n",
    "    def store(self, *args):\n",
    "        super().store(*args)\n",
    "        self.tree.add(self.max_priority ** self.alpha, )\n",
    "    \n",
    "    def sample(self, batch_size, collapsed=True):\n",
    "        priorities = torch.empty(batch_size, 1, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self, policy, result_file_name, use_metrics, time):\n",
    "        self.use_metrics = use_metrics\n",
    "        if not self.use_metrics:\n",
    "            return\n",
    "        new_num = str(len(os.listdir(\"./\" +result_file_name)) + 1)\n",
    "        file_name = f'{result_file_name}/{policy}_DQN_{new_num}_{time}'\n",
    "        self.writer = SummaryWriter(log_dir=file_name, flush_secs=60)\n",
    "            \n",
    "    def add(self, type, y, x):\n",
    "        if not self.use_metrics:\n",
    "            return\n",
    "        self.writer.add_scalar(type, y, x)\n",
    "    def close(self):\n",
    "        if not self.use_metrics:\n",
    "            return\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import highway_env\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, params):\n",
    "        self.q_net = {}\n",
    "        self.q_target_net = {} \n",
    "        self.optimizer= {}        \n",
    "        \n",
    "        self.policy = params.get(\"policy\", \"CnnPolicy\")        \n",
    "        self.episode_num = params.get(\"episode_num\", 10)\n",
    "\n",
    "        self.epsilon = params.get(\"epsilon_max \", 1)\n",
    "        self.epsilon_min = params.get(\"epsilon_min \", 0.1)\n",
    "        self.epsilon_decay = params.get(\"epsilon_decay\", 0.995)\n",
    "        \n",
    "        self.learning_rate = params.get(\"learning_rate\", 5e-4)\n",
    "        self.discount = params.get(\"discount\", 0.2)\n",
    "        self.batch_size = params.get(\"batch_size\", 32)\n",
    "        self.device = params.get(\"device\", torch.device(\"cpu\"))\n",
    "        \n",
    "        self.memory_capacity = params.get(\"memory_capacity\", 1000)\n",
    "        self.memory = {} # this is the memory buffer -> setting a limit\n",
    "        self.n_steps = params.get(\"n_steps\", 2)\n",
    "        self.prioritize_memory = params.get(\"prioritize_memory\", False)\n",
    "        \n",
    "        self.double = params.get(\"double\", False)\n",
    "        \n",
    "        self.timeout = params.get(\"timeout_minute\", 0) * 60 # in minutes\n",
    "        ct = datetime.datetime.now()\n",
    "        self.time = str(ct).replace(\" \", \"|\")\n",
    "        self.to_save_model = params.get(\"save_model\", False)\n",
    "        \n",
    "        use_metrics = params.get(\"use_metrics\", False)\n",
    "        if use_metrics:\n",
    "            self.create_folder(\"training_results\")\n",
    "            # self.save_params(params)\n",
    "            \n",
    "        self.metrics = Metrics(self.policy, \"training_results\", use_metrics, self.time)\n",
    "        \n",
    "    def initialize_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            # Xavier initialization for Conv2d weights\n",
    "            init.xavier_uniform_(m.weight)\n",
    "            init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            # Xavier initialization for Linear weights\n",
    "            init.xavier_uniform_(m.weight)\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "    def create_network(self, env):\n",
    "        if self.policy == \"CnnPolicy\":\n",
    "            self.create_CNN(env)\n",
    "        \n",
    "        if self.policy == \"MlpPolicy\":\n",
    "            self.create_MLP_Network(env)\n",
    "        \n",
    "        self.q_net.apply(self.initialize_weights)    \n",
    "        self.update_target_network()\n",
    "        self.optimizer = optim.Adam(self.q_net.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "    \n",
    "    def create_CNN(self, env):\n",
    "        self.num_states = env.observation_space.shape\n",
    "        self.num_actions = env.action_space.n\n",
    "\n",
    "        self.q_net = CNN(self.num_states, self.num_actions).to(self.device)\n",
    "        self.q_target_net = CNN(self.num_states, self.num_actions).to(self.device)\n",
    "        \n",
    "    \n",
    "    def create_MLP_Network(self, env):\n",
    "        # the lanes\n",
    "        self.num_states = env.observation_space.shape[1]\n",
    "        self.num_actions = env.action_space.n\n",
    "\n",
    "        self.q_net = MLPNetwork(self.num_states, self.num_states, self.num_actions).to(self.device)\n",
    "        self.q_target_net = MLPNetwork(self.num_states, self.num_states, self.num_actions).to(self.device)\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        self.q_target_net.load_state_dict(self.q_net.state_dict())\n",
    "    \n",
    "    def learn(self, env):\n",
    "        self.create_network(env)\n",
    "        \n",
    "        # if (self.prioritize_memory):\n",
    "        self.memory = ReplayMemory({\n",
    "            \"capacity\": self.memory_capacity,\n",
    "            \"device\": self.device,\n",
    "            \"n_steps\": self.n_steps,\n",
    "        })\n",
    "\n",
    "        self.prefill_memory(env, self.batch_size)\n",
    "\n",
    "        start_time = time.time()        \n",
    "        \n",
    "        for epoch in tqdm(range(self.episode_num), desc=\"Training Model\"):\n",
    "            state = env.reset()[0]\n",
    "            \n",
    "            # True when agent reaches the end states (colliding or passing the time)\n",
    "            done = False \n",
    "            \n",
    "            # TODO: see how many actions until truncate\n",
    "            # True when agent takes more than some actions \n",
    "            truncated = False\n",
    "            episode_rewards = []\n",
    "            episode_loss = []\n",
    "            episode_len = 0\n",
    "            while(not done and not truncated):\n",
    "                # choose best action\n",
    "                action = self.get_action(state)\n",
    "                next_state, reward, done, truncated, _ = env.step(action)\n",
    "                self.memory.store(state, action, next_state, reward, done)\n",
    "                \n",
    "                episode_loss.append(self.experience_replay())\n",
    "                \n",
    "                state = next_state\n",
    "                \n",
    "                episode_rewards.append(reward)\n",
    "                episode_len += 1\n",
    "                \n",
    "            self.metrics.add(\"rollout/rewards\", sum(episode_rewards) / len(episode_rewards), epoch)\n",
    "            self.metrics.add(\"rollout/exploration-rate\", self.epsilon, epoch)\n",
    "            self.metrics.add(\"rollout/episode-length\", episode_len, epoch)\n",
    "            self.metrics.add(\"train/loss\", sum(episode_loss) / len(episode_loss), epoch)\n",
    "            \n",
    "            if self.timeout:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                if elapsed_time > self.timeout:\n",
    "                    print(\"Timeout reached. Stopping training.\\n\")\n",
    "                    break\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                self.decay_epsilon()\n",
    "                self.update_target_network()\n",
    "            \n",
    "        self.metrics.close()\n",
    "        \n",
    "        if self.to_save_model:\n",
    "            self.save_model()\n",
    "        \n",
    "    # either the policies are able to get miltuple actions and into the NN or the input of NN should be able to handle all of these\n",
    "    # output (one of): {0: 'LANE_LEFT', 1: 'IDLE', 2: 'LANE_RIGHT', 3: 'FASTER', 4: 'SLOWER'}\n",
    "    def get_action(self, state, eval_mode=False):\n",
    "        if random.random() <= self.epsilon and not eval_mode: # amount of exploration reduces with the epsilon value\n",
    "            return random.randrange(self.num_actions)\n",
    "        \n",
    "        state = torch.tensor(np.array([state]), dtype=torch.float32).to(self.device)\n",
    "        actions = self.q_net(state)\n",
    "        return torch.argmax(actions).item()             \n",
    "\n",
    "    def experience_replay(self):\n",
    "        states, actions, next_states, rewards, dones = self.memory.sample(self.batch_size)\n",
    "        \n",
    "        q_pred = self.q_net(states)\n",
    "        # q value of the action taken\n",
    "        q_pred = q_pred.gather(1, actions.view(-1, 1)) \n",
    "        q_pred = q_pred.squeeze(1)\n",
    "\n",
    "        # Double DQN\n",
    "        if self.double:\n",
    "             # pick best actions from policy network\n",
    "            q_best_action = self.q_net(next_states)\n",
    "            _, q_best_action = q_best_action.max(dim=1)\n",
    "            q_best_action = q_best_action.unsqueeze(1)\n",
    "            \n",
    "            # use those actions for the target policy\n",
    "            q_target = self.q_target_net(next_states)\n",
    "            q_target = q_target.gather(1, q_best_action)\n",
    "            q_target = q_target.squeeze(1)\n",
    "        else:\n",
    "            q_target = self.q_target_net(next_states)\n",
    "            q_target = q_target.max(dim=1).values\n",
    "        \n",
    "        # setting Q(s',a') to 0 when the current state is a terminal state\n",
    "        q_target[dones] = 0.0\n",
    "        \n",
    "        y_j = rewards + (self.discount * q_target)\n",
    "        \n",
    "        # calculate the loss as the mean-squared error of yj and qpred\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = F.mse_loss(y_j, q_pred).mean()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "        \n",
    "    def prefill_memory(self, env, prefill_num):\n",
    "        for _ in tqdm(range(prefill_num), desc=\"Prefilling Memory \"):\n",
    "            done = False\n",
    "            truncated = False\n",
    "            state = env.reset()[0]\n",
    "\n",
    "            while not done and not truncated:\n",
    "                action = env.action_space.sample()\n",
    "                next_state, reward, done, truncated, info = env.step(action)\n",
    "                self.memory.store(state, action, next_state, reward, done)    \n",
    "                \n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon*self.epsilon_decay)\n",
    "    \n",
    "    def evaluate(self, env, episode_num):\n",
    "        # add camera here\n",
    "        for _ in tqdm(range(episode_num), desc=\"Evaluating Model\"):\n",
    "            state = env.reset()[0]  \n",
    "            done = False      \n",
    "            truncated = False \n",
    "\n",
    "            # Agent navigates map until it falls into a hole (terminated), reaches goal (terminated), or has taken 200 actions (truncated).\n",
    "            while(not done and not truncated):  \n",
    "                # Select best action   \n",
    "                action = self.get_action(state, eval_mode=True)\n",
    "                next_state, reward, done, truncated, info = env.step(action)\n",
    "                state = next_state\n",
    "                env.render()\n",
    "        \n",
    "    def save_model(self):\n",
    "        folder_name = self.policy + \"_save_models\"\n",
    "        self.create_folder(folder_name)\n",
    "        new_model_num = str(len(os.listdir(\"./\" +folder_name)) + 1)\n",
    "        file_name = f'{folder_name}/DQN_{new_model_num}_{self.time}.pth'\n",
    "        state = {'state_dict': self.q_net.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict()}\n",
    "        torch.save(state, file_name)\n",
    "        \n",
    "    def load_model(self, env, file_name):\n",
    "        folder_name = self.policy + \"_save_models\"\n",
    "                \n",
    "        filename = folder_name + \"/\" + file_name + \".pth\"\n",
    "        self.create_network(env)\n",
    "        \n",
    "        models = torch.load(filename, map_location=self.device)\n",
    "        \n",
    "        self.q_net.load_state_dict(models['state_dict'])\n",
    "        self.optimizer.load_state_dict(models['optimizer'])\n",
    "    \n",
    "    def save_params(self, params):\n",
    "        folder_name = \"hyperparameters\"\n",
    "        self.create_folder(folder_name)\n",
    "        \n",
    "        file_name = f'./{folder_name}/{self.policy}_DQN_{self.time}'\n",
    "        with open(file_name + '.txt', 'w') as file:\n",
    "            file.write(json.dumps(str(params)))\n",
    "\n",
    "    def create_folder(self, directory_name):\n",
    "        try:\n",
    "            os.mkdir(directory_name)\n",
    "            print(f\"Directory '{directory_name}' created successfully.\")\n",
    "        except FileExistsError:\n",
    "            return\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied: Unable to create '{directory_name}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "policy = \"CnnPolicy\"\n",
    "# policy = \"MlpPolicy\"\n",
    "\n",
    "if policy == \"CnnPolicy\":\n",
    "    config={\n",
    "        \"lanes_count\" : 3,\n",
    "        \"observation\": {\n",
    "            \"type\": \"GrayscaleObservation\",\n",
    "            \"observation_shape\": (128, 64),\n",
    "            \"stack_size\": 4,\n",
    "            \"weights\": [0.2989, 0.5870, 0.1140],  # weights for RGB conversion keep this conversion this is in the highway env page\n",
    "            \"scaling\": 1.75,\n",
    "        },\n",
    "    }\n",
    "else:\n",
    "    config = {\n",
    "        \"lanes_count\" : 3,\n",
    "        \"observation\": {\n",
    "            \"type\": \"Kinematics\",\n",
    "            \"vehicles_count\": 5,\n",
    "            \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\", \"cos_h\", \"sin_h\"],\n",
    "            \"features_range\": {\n",
    "                \"x\": [-100, 100],\n",
    "                \"y\": [-100, 100],\n",
    "                \"vx\": [-20, 20],\n",
    "                \"vy\": [-20, 20]\n",
    "            },\n",
    "            \"absolute\": False,\n",
    "            \"order\": \"sorted\"\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefilling Memory : 100%|██████████| 16/16 [00:02<00:00,  5.34it/s]\n",
      "Training Model:  15%|█▌        | 1523/10000 [15:00<1:23:30,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout reached. Stopping training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefilling Memory : 100%|██████████| 16/16 [00:03<00:00,  5.12it/s]\n",
      "Training Model:  14%|█▍        | 1448/10000 [15:00<1:28:37,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout reached. Stopping training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefilling Memory : 100%|██████████| 16/16 [00:02<00:00,  5.35it/s]\n",
      "Training Model:  15%|█▍        | 1473/10000 [15:00<1:26:51,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout reached. Stopping training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "params = {\n",
    "    'policy' : policy,\n",
    "    'episode_num' : 10000,\n",
    "    'discount' : 0.7,\n",
    "    'batch_size' : 16,\n",
    "    'learning_rate': 5e-6,\n",
    "    'n_steps': 4,\n",
    "    'double': True,\n",
    "    'device' : torch.device(\"mps\"),\n",
    "    'memory_capacity' : 10000,\n",
    "    'timeout_minute': 15,\n",
    "    'use_metrics' : True,\n",
    "    'save_model': True,\n",
    "}\n",
    "\n",
    "for seed in range(3):\n",
    "    torch.manual_seed(seed)\n",
    "    dqn_agent = DQNAgent(params)\n",
    "    env = gym.make('highway-fast-v0', render_mode='rgb_array', config=config)\n",
    "    dqn_agent.learn(env)\n",
    "\n",
    "# env = gym.make('highway-v0', render_mode='rgb_array', config=config)\n",
    "# dqn_agent.evaluate(env, 5)\n",
    "\n",
    "# if you wanna save a model again\n",
    "# dqn_agent.save_model(\"highway_dqn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/m_r158w50cqfn3ydymrpm7rc0000gn/T/ipykernel_63725/1993401512.py:240: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  models = torch.load(filename, map_location=self.device)\n",
      "Evaluating Model:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0185, 0.2510, 0.2137, 0.1976, 0.3192]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4049, 0.4373, 0.0794, 0.0192, 0.0591]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0151, 0.8696, 0.0988, 0.0057, 0.0108]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1319, 0.3868, 0.3957, 0.0533, 0.0323]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0477, 0.3249, 0.4347, 0.0774, 0.1153]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0148, 0.0608, 0.6403, 0.0468, 0.2372]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0093, 0.0891, 0.6170, 0.2387, 0.0459]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0201, 0.3056, 0.4747, 0.1253, 0.0744]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0129, 0.6341, 0.1415, 0.0842, 0.1273]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0917, 0.2915, 0.3395, 0.1494, 0.1278]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0580, 0.4776, 0.2491, 0.1318, 0.0834]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0972, 0.2812, 0.1812, 0.3211, 0.1193]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1144, 0.4652, 0.1707, 0.1388, 0.1109]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1937, 0.1504, 0.4699, 0.0285, 0.1575]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0294, 0.3498, 0.3900, 0.0725, 0.1584]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1918, 0.1199, 0.0717, 0.3875, 0.2291]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0328, 0.1046, 0.6122, 0.0621, 0.1882]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0253, 0.2577, 0.0955, 0.5990, 0.0224]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1224, 0.0400, 0.0680, 0.4503, 0.3194]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:   5%|▌         | 1/20 [00:04<01:30,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0221, 0.3604, 0.4267, 0.0916, 0.0992]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3926, 0.0366, 0.5376, 0.0075, 0.0257]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0572, 0.3040, 0.4567, 0.1623, 0.0198]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0435, 0.3207, 0.0895, 0.2204, 0.3258]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0789, 0.3173, 0.3057, 0.2595, 0.0386]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0073, 0.4538, 0.3775, 0.1127, 0.0487]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0149, 0.1094, 0.1438, 0.6891, 0.0428]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0276, 0.6583, 0.0192, 0.0200, 0.2750]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0413, 0.0296, 0.3465, 0.5556, 0.0270]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0878, 0.0422, 0.3482, 0.1348, 0.3870]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2051, 0.0829, 0.1628, 0.0557, 0.4934]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0362, 0.1408, 0.6393, 0.1078, 0.0759]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0074, 0.0736, 0.7718, 0.0167, 0.1305]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0644, 0.1183, 0.1057, 0.2492, 0.4624]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0179, 0.1354, 0.3941, 0.0790, 0.3736]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1328, 0.1939, 0.3449, 0.1652, 0.1632]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0340, 0.6680, 0.1934, 0.0097, 0.0949]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5430, 0.0974, 0.2318, 0.0279, 0.0999]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3400, 0.0389, 0.5807, 0.0065, 0.0339]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0717, 0.1650, 0.0144, 0.0185, 0.7304]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2308, 0.0987, 0.1111, 0.0307, 0.5286]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0036, 0.0315, 0.1163, 0.7675, 0.0811]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0349, 0.1102, 0.5503, 0.2509, 0.0536]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2778, 0.1911, 0.3186, 0.0614, 0.1511]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0553, 0.2066, 0.3167, 0.2782, 0.1432]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1383, 0.4243, 0.1739, 0.1754, 0.0881]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2078, 0.2443, 0.1716, 0.3326, 0.0437]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0880, 0.4591, 0.1337, 0.1600, 0.1593]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1148, 0.4118, 0.1716, 0.1411, 0.1607]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1737, 0.3953, 0.2142, 0.0493, 0.1674]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0955, 0.1118, 0.2497, 0.5194, 0.0236]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2524, 0.1964, 0.1085, 0.3490, 0.0937]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0137, 0.0459, 0.3595, 0.2151, 0.3658]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0608, 0.1563, 0.5566, 0.1421, 0.0841]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1672, 0.0309, 0.6562, 0.1329, 0.0127]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0194, 0.1467, 0.1657, 0.1824, 0.4857]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1648, 0.3026, 0.2383, 0.0660, 0.2284]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1109, 0.0955, 0.2028, 0.1198, 0.4710]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0682, 0.3268, 0.2983, 0.1463, 0.1604]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2037, 0.2278, 0.4310, 0.0544, 0.0831]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  10%|█         | 2/20 [00:14<02:22,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0904, 0.2062, 0.4016, 0.1765, 0.1253]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0052, 0.0029, 0.9794, 0.0017, 0.0109]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[2.7469e-02, 1.1363e-02, 8.5962e-01, 8.0729e-05, 1.0147e-01]],\n",
      "       device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[2.2540e-02, 5.7082e-02, 6.5208e-02, 5.1390e-04, 8.5466e-01]],\n",
      "       device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0568, 0.1195, 0.0776, 0.0400, 0.7061]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0032, 0.0219, 0.9220, 0.0071, 0.0458]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1514, 0.1244, 0.3737, 0.1196, 0.2310]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5780, 0.0806, 0.1396, 0.0167, 0.1851]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4861, 0.0193, 0.4086, 0.0028, 0.0832]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6654, 0.0310, 0.0382, 0.0853, 0.1801]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2881, 0.0575, 0.4816, 0.0095, 0.1634]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2687, 0.0066, 0.4462, 0.2444, 0.0342]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  15%|█▌        | 3/20 [00:17<01:36,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1103, 0.1489, 0.4807, 0.1402, 0.1200]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0303, 0.0268, 0.7640, 0.0433, 0.1356]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[7.8247e-02, 1.8874e-01, 5.0547e-01, 1.9150e-04, 2.2735e-01]],\n",
      "       device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7103, 0.0608, 0.1123, 0.0174, 0.0992]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  20%|██        | 4/20 [00:18<01:01,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0458, 0.2912, 0.3854, 0.1823, 0.0952]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0026, 0.0041, 0.9701, 0.0073, 0.0160]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0923, 0.5949, 0.2589, 0.0008, 0.0532]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0225, 0.2183, 0.5709, 0.0011, 0.1872]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0060, 0.0064, 0.8961, 0.0478, 0.0437]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0121, 0.0633, 0.4721, 0.3611, 0.0915]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0102, 0.4078, 0.3536, 0.1421, 0.0864]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0928, 0.1084, 0.2678, 0.4141, 0.1169]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5026, 0.2499, 0.0919, 0.0334, 0.1222]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0692, 0.2350, 0.1050, 0.1906, 0.4001]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3045, 0.0292, 0.1377, 0.0129, 0.5156]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2551, 0.5325, 0.0442, 0.1196, 0.0487]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0881, 0.6199, 0.2114, 0.0376, 0.0430]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0645, 0.1106, 0.0574, 0.4586, 0.3089]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3908, 0.0906, 0.0354, 0.0557, 0.4275]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0301, 0.3885, 0.0688, 0.3585, 0.1540]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0234, 0.1442, 0.0086, 0.5796, 0.2441]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0528, 0.1305, 0.0120, 0.4301, 0.3746]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0106, 0.3914, 0.0189, 0.4365, 0.1426]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2167, 0.1666, 0.0267, 0.4009, 0.1890]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0694, 0.1683, 0.0076, 0.5841, 0.1706]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0560, 0.5016, 0.0568, 0.0610, 0.3247]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  25%|██▌       | 5/20 [00:24<01:06,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1584, 0.4283, 0.2946, 0.0299, 0.0888]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6712, 0.0508, 0.2630, 0.0060, 0.0089]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1182, 0.8329, 0.0124, 0.0039, 0.0326]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4088, 0.3958, 0.0684, 0.0837, 0.0433]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1599, 0.0382, 0.2841, 0.0561, 0.4617]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0556, 0.0197, 0.8183, 0.0896, 0.0168]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0694, 0.5926, 0.2760, 0.0093, 0.0527]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0483, 0.0698, 0.7664, 0.0185, 0.0970]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0009, 0.0155, 0.5639, 0.3881, 0.0316]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2978, 0.1102, 0.4521, 0.0731, 0.0668]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0129, 0.0589, 0.3219, 0.5868, 0.0196]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0611, 0.0286, 0.4509, 0.2963, 0.1631]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1169, 0.2524, 0.4634, 0.0251, 0.1422]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0545, 0.2096, 0.4351, 0.0788, 0.2220]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2853, 0.1167, 0.3361, 0.0703, 0.1916]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1056, 0.0799, 0.5176, 0.1073, 0.1895]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0319, 0.4450, 0.4396, 0.0366, 0.0468]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0364, 0.0531, 0.8734, 0.0115, 0.0256]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0108, 0.4743, 0.2050, 0.2034, 0.1065]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  30%|███       | 6/20 [00:29<01:03,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0654, 0.1330, 0.4584, 0.2436, 0.0997]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0947, 0.0164, 0.8249, 0.0321, 0.0319]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1763, 0.2033, 0.5796, 0.0062, 0.0346]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2534, 0.0475, 0.2149, 0.2994, 0.1848]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2373, 0.2251, 0.3746, 0.0568, 0.1061]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  35%|███▌      | 7/20 [00:30<00:45,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0766, 0.3468, 0.2130, 0.1099, 0.2537]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4495, 0.1051, 0.3932, 0.0283, 0.0239]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0743, 0.2425, 0.4851, 0.0021, 0.1960]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1584, 0.3289, 0.0394, 0.0168, 0.4565]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5149, 0.0122, 0.3429, 0.0247, 0.1052]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0024, 0.0118, 0.7903, 0.1343, 0.0612]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[2.5872e-02, 8.3777e-02, 3.2015e-04, 1.2443e-01, 7.6561e-01]],\n",
      "       device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0079, 0.3610, 0.1351, 0.0537, 0.4423]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0119, 0.5447, 0.3017, 0.0702, 0.0714]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0029, 0.0276, 0.8959, 0.0615, 0.0122]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0605, 0.2198, 0.3601, 0.3110, 0.0486]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0272, 0.2531, 0.3461, 0.1727, 0.2009]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1246, 0.6079, 0.0926, 0.1126, 0.0623]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0241, 0.7863, 0.0827, 0.0347, 0.0721]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1591, 0.1227, 0.3564, 0.1443, 0.2175]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0323, 0.1143, 0.1486, 0.2206, 0.4842]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0497, 0.1143, 0.3490, 0.0913, 0.3958]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0235, 0.3737, 0.3032, 0.0378, 0.2618]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1408, 0.2512, 0.2163, 0.0536, 0.3380]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0574, 0.3280, 0.4937, 0.0299, 0.0910]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0217, 0.1634, 0.3303, 0.4082, 0.0763]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0154, 0.1817, 0.6601, 0.0550, 0.0878]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1577, 0.1743, 0.3776, 0.0872, 0.2032]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0403, 0.3145, 0.3091, 0.1216, 0.2145]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4352, 0.0232, 0.1015, 0.1228, 0.3173]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  40%|████      | 8/20 [00:36<00:52,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0816, 0.0539, 0.2977, 0.1495, 0.4174]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0811, 0.1930, 0.6008, 0.1019, 0.0231]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0531, 0.2177, 0.6842, 0.0205, 0.0246]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0480, 0.0698, 0.7894, 0.0311, 0.0617]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0572, 0.1081, 0.7356, 0.0252, 0.0739]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0723, 0.1166, 0.4220, 0.1368, 0.2523]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0084, 0.1229, 0.4982, 0.0557, 0.3149]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0430, 0.0334, 0.7343, 0.0534, 0.1358]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0579, 0.4632, 0.3902, 0.0203, 0.0684]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0107, 0.2847, 0.3671, 0.2291, 0.1084]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1182, 0.3293, 0.3205, 0.0324, 0.1997]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0561, 0.2554, 0.2798, 0.0313, 0.3775]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0403, 0.0231, 0.6130, 0.0257, 0.2979]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0294, 0.1194, 0.1570, 0.1331, 0.5611]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0204, 0.1088, 0.7075, 0.0325, 0.1308]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0308, 0.3907, 0.3142, 0.0723, 0.1920]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1653, 0.1562, 0.3472, 0.1180, 0.2133]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0404, 0.2265, 0.4349, 0.1367, 0.1615]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1581, 0.1167, 0.0920, 0.3242, 0.3091]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1297, 0.1976, 0.2091, 0.1414, 0.3223]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0859, 0.0632, 0.2856, 0.0670, 0.4984]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0451, 0.2790, 0.1844, 0.1139, 0.3775]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0539, 0.2314, 0.4352, 0.0273, 0.2521]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1641, 0.3373, 0.3370, 0.0803, 0.0814]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0148, 0.3036, 0.2761, 0.1195, 0.2860]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0264, 0.0436, 0.3536, 0.1027, 0.4737]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0408, 0.2061, 0.4254, 0.0286, 0.2992]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3770, 0.2001, 0.1732, 0.0128, 0.2368]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3236, 0.0384, 0.4112, 0.0199, 0.2069]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1374, 0.1188, 0.0875, 0.0184, 0.6380]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1708, 0.0112, 0.1763, 0.0037, 0.6380]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0094, 0.0016, 0.5298, 0.1363, 0.3229]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0871, 0.0573, 0.7730, 0.0424, 0.0401]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0855, 0.0954, 0.6202, 0.1024, 0.0966]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0284, 0.2005, 0.1764, 0.4224, 0.1723]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0360, 0.1483, 0.3198, 0.2626, 0.2332]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0147, 0.1011, 0.3905, 0.0256, 0.4681]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0043, 0.1794, 0.0912, 0.1249, 0.6002]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1813, 0.1724, 0.1228, 0.2470, 0.2765]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0413, 0.4368, 0.2821, 0.0389, 0.2009]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  45%|████▌     | 9/20 [00:47<01:08,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0532, 0.1181, 0.2796, 0.1180, 0.4311]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3258, 0.1338, 0.3246, 0.1651, 0.0507]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1305, 0.1592, 0.4137, 0.0270, 0.2695]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3173, 0.0047, 0.2095, 0.0260, 0.4426]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0645, 0.0254, 0.5951, 0.0023, 0.3128]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0936, 0.0070, 0.2582, 0.3290, 0.3122]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2346, 0.0313, 0.3890, 0.1543, 0.1907]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1393, 0.2431, 0.1262, 0.3163, 0.1750]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6054, 0.2977, 0.0356, 0.0085, 0.0529]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8991, 0.0129, 0.0610, 0.0148, 0.0121]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4779, 0.1593, 0.1486, 0.0042, 0.2100]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  50%|█████     | 10/20 [00:49<00:51,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0827, 0.2503, 0.2746, 0.0910, 0.3014]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1000, 0.0544, 0.6303, 0.1392, 0.0762]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2208, 0.2938, 0.4295, 0.0060, 0.0499]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0690, 0.0623, 0.4526, 0.2813, 0.1348]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0797, 0.1690, 0.3062, 0.2140, 0.2312]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0290, 0.0689, 0.6545, 0.0553, 0.1923]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0107, 0.1505, 0.6268, 0.0609, 0.1511]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0551, 0.0908, 0.7512, 0.0280, 0.0749]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0081, 0.1685, 0.4479, 0.2558, 0.1197]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0666, 0.3009, 0.4779, 0.0806, 0.0741]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0172, 0.3749, 0.3879, 0.0564, 0.1636]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0673, 0.0929, 0.4736, 0.1498, 0.2164]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0299, 0.0838, 0.6292, 0.0963, 0.1608]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0268, 0.2110, 0.3723, 0.1147, 0.2751]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0116, 0.5322, 0.3076, 0.0157, 0.1329]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1593, 0.1670, 0.4037, 0.0405, 0.2295]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0433, 0.2928, 0.4875, 0.0319, 0.1446]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0326, 0.2986, 0.1811, 0.2318, 0.2559]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0122, 0.1591, 0.5651, 0.0496, 0.2140]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0778, 0.1967, 0.5850, 0.0463, 0.0942]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0684, 0.4245, 0.3346, 0.0951, 0.0773]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0114, 0.2818, 0.3682, 0.1393, 0.1993]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0178, 0.1846, 0.4789, 0.0403, 0.2783]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0960, 0.2834, 0.5073, 0.0154, 0.0980]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0382, 0.1718, 0.7214, 0.0116, 0.0571]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1195, 0.3529, 0.2636, 0.1341, 0.1298]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0171, 0.1544, 0.5928, 0.0707, 0.1650]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0136, 0.2183, 0.6417, 0.0185, 0.1079]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0564, 0.1860, 0.6580, 0.0156, 0.0841]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0129, 0.2634, 0.5277, 0.0694, 0.1265]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1679, 0.3570, 0.3161, 0.0580, 0.1010]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0223, 0.2512, 0.5263, 0.0252, 0.1749]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0285, 0.0511, 0.7670, 0.0266, 0.1269]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0232, 0.1861, 0.4194, 0.1427, 0.2286]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0658, 0.3131, 0.1837, 0.1691, 0.2683]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0131, 0.4322, 0.2033, 0.0950, 0.2565]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1891, 0.4209, 0.1987, 0.0474, 0.1439]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0774, 0.3826, 0.4057, 0.0429, 0.0914]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1107, 0.1808, 0.1798, 0.3388, 0.1899]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0386, 0.0991, 0.5213, 0.0770, 0.2639]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  55%|█████▌    | 11/20 [00:59<00:59,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0447, 0.0710, 0.7855, 0.0380, 0.0608]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0051, 0.0062, 0.9253, 0.0056, 0.0578]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0133, 0.3600, 0.4443, 0.0040, 0.1784]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4560, 0.0666, 0.1143, 0.0139, 0.3493]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3928, 0.0026, 0.2906, 0.0243, 0.2898]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3232, 0.0226, 0.0839, 0.0917, 0.4787]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0269, 0.4367, 0.3951, 0.0026, 0.1387]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2258, 0.3510, 0.1272, 0.2080, 0.0881]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2468, 0.4994, 0.0582, 0.0764, 0.1193]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1253, 0.3093, 0.0824, 0.4649, 0.0182]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2935, 0.2207, 0.0989, 0.3716, 0.0153]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3039, 0.2855, 0.1893, 0.0982, 0.1231]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1735, 0.4217, 0.1509, 0.1501, 0.1039]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0622, 0.3191, 0.1553, 0.4458, 0.0177]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0515, 0.2127, 0.1175, 0.4927, 0.1255]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0404, 0.0671, 0.7505, 0.0484, 0.0936]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  60%|██████    | 12/20 [01:04<00:47,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1481, 0.4816, 0.2636, 0.0325, 0.0742]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5156, 0.1671, 0.1735, 0.0062, 0.1376]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6233, 0.3057, 0.0247, 0.0184, 0.0279]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1598, 0.3132, 0.1733, 0.3399, 0.0138]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0463, 0.1030, 0.5464, 0.0496, 0.2547]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0376, 0.0407, 0.0160, 0.8917, 0.0140]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0150, 0.1381, 0.7517, 0.0494, 0.0459]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  65%|██████▌   | 13/20 [01:05<00:32,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0766, 0.3011, 0.1475, 0.0324, 0.4424]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3038, 0.1979, 0.2097, 0.1233, 0.1654]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0370, 0.5247, 0.3281, 0.0010, 0.1093]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2374, 0.0407, 0.0519, 0.0357, 0.6344]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6052, 0.1271, 0.0264, 0.1971, 0.0442]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4880, 0.1392, 0.1228, 0.0206, 0.2295]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4669, 0.2114, 0.0286, 0.0684, 0.2247]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1526, 0.1594, 0.2683, 0.3505, 0.0691]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0411, 0.2163, 0.5465, 0.1654, 0.0307]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1661, 0.5460, 0.1939, 0.0465, 0.0474]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0640, 0.3339, 0.3927, 0.1469, 0.0625]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  70%|███████   | 14/20 [01:08<00:24,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0575, 0.2738, 0.2200, 0.3308, 0.1180]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2610, 0.5088, 0.1200, 0.0132, 0.0969]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1101, 0.1673, 0.7044, 0.0019, 0.0162]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  75%|███████▌  | 15/20 [01:09<00:15,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3106, 0.1816, 0.2329, 0.1450, 0.1299]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2396, 0.3635, 0.1694, 0.0805, 0.1470]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0208, 0.3036, 0.2062, 0.0792, 0.3902]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2232, 0.1363, 0.4809, 0.1421, 0.0174]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  80%|████████  | 16/20 [01:10<00:09,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1771, 0.0909, 0.2946, 0.2666, 0.1709]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5044, 0.0902, 0.2631, 0.0286, 0.1137]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0143, 0.1613, 0.4874, 0.0022, 0.3347]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1324, 0.0677, 0.1658, 0.0311, 0.6030]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2679, 0.0371, 0.4115, 0.0214, 0.2621]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  85%|████████▌ | 17/20 [01:11<00:06,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0100, 0.2667, 0.4419, 0.1587, 0.1227]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3149, 0.5005, 0.0892, 0.0761, 0.0193]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0525, 0.5910, 0.3385, 0.0052, 0.0128]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0237, 0.0603, 0.5692, 0.0205, 0.3264]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0113, 0.2258, 0.3678, 0.2581, 0.1370]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0325, 0.1075, 0.5599, 0.1017, 0.1984]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0121, 0.2718, 0.2993, 0.3194, 0.0973]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2143, 0.0857, 0.5692, 0.0830, 0.0478]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1245, 0.0151, 0.1517, 0.5701, 0.1386]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0268, 0.2788, 0.1802, 0.1215, 0.3927]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5575, 0.0878, 0.2648, 0.0193, 0.0706]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  90%|█████████ | 18/20 [01:14<00:04,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0307, 0.1646, 0.5378, 0.2169, 0.0500]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4875, 0.0699, 0.3521, 0.0706, 0.0199]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1435, 0.4581, 0.3153, 0.0010, 0.0821]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0103, 0.2525, 0.5590, 0.1259, 0.0523]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0593, 0.0395, 0.1893, 0.2003, 0.5115]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0472, 0.0711, 0.1127, 0.3710, 0.3979]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0126, 0.1423, 0.6838, 0.0652, 0.0961]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0024, 0.2011, 0.6734, 0.0880, 0.0351]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1488, 0.2993, 0.4740, 0.0458, 0.0322]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2306, 0.4885, 0.2316, 0.0243, 0.0250]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0698, 0.3471, 0.3255, 0.0875, 0.1701]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0704, 0.2082, 0.4912, 0.1390, 0.0912]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0860, 0.5769, 0.1344, 0.0882, 0.1144]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0114, 0.0652, 0.7321, 0.1361, 0.0552]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0074, 0.0913, 0.7157, 0.0551, 0.1305]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0223, 0.1293, 0.5065, 0.0815, 0.2604]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0058, 0.2399, 0.7065, 0.0064, 0.0413]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2630, 0.4621, 0.2006, 0.0085, 0.0658]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0166, 0.8881, 0.0874, 0.0031, 0.0049]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0482, 0.3624, 0.3206, 0.2310, 0.0378]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0339, 0.2946, 0.2656, 0.0384, 0.3674]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0312, 0.0307, 0.6887, 0.0814, 0.1680]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0194, 0.0918, 0.3311, 0.1999, 0.3578]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0143, 0.1148, 0.6926, 0.0486, 0.1297]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0061, 0.0406, 0.8096, 0.0045, 0.1392]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0353, 0.3896, 0.5012, 0.0168, 0.0571]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1525, 0.1628, 0.5354, 0.1015, 0.0477]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0171, 0.7159, 0.0710, 0.1112, 0.0848]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0443, 0.3098, 0.5056, 0.0851, 0.0552]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0209, 0.3920, 0.3585, 0.0559, 0.1727]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0882, 0.2101, 0.2388, 0.4072, 0.0559]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0085, 0.1526, 0.6547, 0.0727, 0.1115]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0511, 0.5466, 0.2842, 0.0562, 0.0619]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0091, 0.0909, 0.3193, 0.1737, 0.4070]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2846, 0.1508, 0.2905, 0.1652, 0.1088]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3447, 0.0920, 0.3512, 0.0651, 0.1470]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0858, 0.1832, 0.2930, 0.0443, 0.3937]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1058, 0.1081, 0.5271, 0.1015, 0.1576]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0232, 0.1256, 0.6031, 0.0659, 0.1823]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2778, 0.1184, 0.4740, 0.0844, 0.0453]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model:  95%|█████████▌| 19/20 [01:24<00:04,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0850, 0.2078, 0.2198, 0.2026, 0.2847]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0679, 0.6665, 0.1065, 0.0285, 0.1306]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0107, 0.6353, 0.2254, 0.0317, 0.0969]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1768, 0.3929, 0.1705, 0.2140, 0.0457]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1787, 0.1172, 0.0955, 0.5234, 0.0852]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0756, 0.1094, 0.5357, 0.1828, 0.0964]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0094, 0.1014, 0.8182, 0.0552, 0.0158]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2297, 0.0324, 0.6684, 0.0154, 0.0542]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2438, 0.0510, 0.1469, 0.0014, 0.5570]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0069, 0.0441, 0.2712, 0.0222, 0.6556]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0097, 0.0208, 0.7784, 0.0857, 0.1053]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1521, 0.2104, 0.2307, 0.2581, 0.1487]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0078, 0.0835, 0.6552, 0.2279, 0.0256]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0408, 0.0471, 0.8336, 0.0079, 0.0706]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0258, 0.1938, 0.4406, 0.1786, 0.1611]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3584, 0.0950, 0.1975, 0.2397, 0.1094]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0987, 0.0334, 0.7481, 0.0307, 0.0891]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1465, 0.3790, 0.0468, 0.0644, 0.3633]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3028, 0.0071, 0.5480, 0.0021, 0.1401]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0926, 0.0057, 0.3556, 0.3957, 0.1503]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0094, 0.0240, 0.5578, 0.3609, 0.0479]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0129, 0.4725, 0.0967, 0.2779, 0.1401]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0378, 0.1024, 0.0673, 0.0652, 0.7273]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0614, 0.0104, 0.6871, 0.0362, 0.2048]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0545, 0.2976, 0.3833, 0.1557, 0.1088]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0596, 0.1076, 0.4050, 0.1012, 0.3265]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1413, 0.0697, 0.4335, 0.2236, 0.1320]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2794, 0.1537, 0.0847, 0.2444, 0.2379]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1689, 0.1305, 0.4871, 0.0160, 0.1975]], device='mps:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model: 100%|██████████| 20/20 [01:32<00:00,  4.60s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym.make('highway-v0', render_mode='rgb_array', config=config)\n",
    "\n",
    "dqn_agent_test = DQNAgent(params)\n",
    "dqn_agent_test.load_model(env, \"DQN_4_2024-12-24|14:11:48.566160\")\n",
    "\n",
    "dqn_agent_test.evaluate(env, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b95d3aa0fdeff6c3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b95d3aa0fdeff6c3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6010;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir training_results --host localhost --port 6010"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
