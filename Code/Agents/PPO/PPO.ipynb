{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install environment and agent\n",
    "!pip install highway-env\n",
    "!pip install --upgrade sympy torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papers:\n",
    "[Proximal Policy Optimization Algorithms](https://arxiv.org/pdf/1707.06347)\n",
    "\n",
    "[Towards Delivering a Coherent Self-Contained Explanation of Proximal Policy Optimization](https://fse.studenttheses.ub.rug.nl/25709/1/mAI_2021_BickD.pdf)\n",
    "\n",
    "### Tutorial\n",
    "[Hugging Face Deep RL Course: PROXIMAL POLICY OPTIMIZATION (PPO)](https://huggingface.co/learn/deep-rl-course/unit8/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import highway_env\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Policy network (MLP)\n",
    "class MLPPolicyNetwork(nn.Module):\n",
    "    def __init__(self, in_states, h1_nodes, out_actions):\n",
    "        super(MLPPolicyNetwork, self).__init__()\n",
    "\n",
    "        # Actor network\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(in_states, h1_nodes),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h1_nodes, out_actions)\n",
    "        )\n",
    "        # Critic network\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(in_states, h1_nodes),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h1_nodes, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        policy = self.actor(x)\n",
    "        value = self.critic(x)\n",
    "        return policy, value\n",
    "\n",
    "\n",
    "class CNNPolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(CNNPolicyNetwork, self).__init__()\n",
    "        # greyscale Image is(stack,height,width)\n",
    "        stack, height, width = input_shape\n",
    "\n",
    "        # Feature\n",
    "        self.actor_cn = nn.Sequential(\n",
    "            nn.Conv2d(stack, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.critic_cn = nn.Sequential(\n",
    "            nn.Conv2d(stack, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # This is for finding the size to dense more robust compared to decision manually\n",
    "        with torch.no_grad():\n",
    "                # Torch uses(1,channels,height,width)\n",
    "                test = torch.zeros(1, stack, height, width)\n",
    "                find_conv_size = self.conv(test)\n",
    "                conv_size = find_conv_size.numel()\n",
    "\n",
    "\n",
    "        self.actor = nn.Linear(conv_size, action_dim) # Actor network\n",
    "        self.critic = nn.Linear(conv_size, 1) # Critic network\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, stack, height, width]\n",
    "        conv_feats = self.actor_conv(x)\n",
    "        conv_feats = torch.flatten(conv_feats, start_dim=1)\n",
    "        policy = self.actor_fc(conv_feats)\n",
    "\n",
    "        conv_feats_critic = self.critic_conv(x)\n",
    "        conv_feats_critic = torch.flatten(conv_feats_critic, start_dim=1)\n",
    "        value = self.critic(critic_feats)\n",
    "\n",
    "        return policy, value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
